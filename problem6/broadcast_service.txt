
BACKEND:
When starting up the broadcasting service, there will be a recovery mechanism to check the database for any transactions that were not successfully broadcasted and repopulate the broadcasting queue with these transactions so that the broadcasting process can resume.

When the API gateway of the broadcasting service receives a new POST request with the necessary details. The broadcasting service will sign the message and pass it into a message queue for it to be broadcast it to an EVM-compatible blockchain network through an RPC request, this allows for persistent storing of transactions in the case of a service restart.

If the broadcast is successful, return "http 200 OK", else if broadcast is being retried return "http 202 ACCEPTED". Furthermore, add in a message indicating the status of the request. However, return 400/500 for input validation of the input data.

Whenever the broadcast fails, the broadcasting service will send the failed message with metadata (ie. number of retries) into the retry message queue that stores failed messages with the purpose of retrying the broadcasting.

So currently the broadcasting service is able to handle concurrent broadcasting through async methods, this for simultaneous processing of new messages from the API gateway as well as the failed messages from the retry message queue.
   - Worker Pool Pattern: Create a fixed number of goroutines (workers) that listen on the retry channel. These workers process messages as they come in. This approach limits the number of concurrent operations, providing a safeguard against resource exhaustion. [method for handling currency]

The transaction will be saved in the noSQL database with a pending status field first. If successful, it will update the field with a "success" and correspondingly for "fail" based on the transaction ID. The condition for failing is if the broadcast fails 3 times, it will then be removed from the queue.



FRONTEND:
There will be an admin interface to view the broadcast messages and their status. Admin will be able to send a POST request of the "failed" broadcast to the broadcasting service for retrying purposes, however the broadcasting service will not see this as a "retry" but instead as a new message to be broadcasted.

BACKEND:

Service A = API Gateway
Service B = Broadcasting Transaction Service
Requests = Transaction

"A"
1. Incoming POST with the transaction data to be received
2. Once received, validate the data.
3. Send the "New" transaction into the "Request" message channel
3a. When "B" successfully receives the request from the channel, return 200 OK.
4. Stores the transaction details into the DB (txn_id, txn_details, status, attempts, timestamp)
5. Awaits a response from the Broadcasting service for updating of the DB, the response is from the "Response" message channel
6. After receiving a response (status, message, attempts, ...), update the transaction based on the response using the txn_id.


"B"
Upon starting the Broadcasting service, there will be a recovery mechanism to check the database for any transactions that were not successfully broadcasted (no status) and repopulate the request message channel with these transactions so that the broadcasting process can resume.
1. Broadcast the signed transaction using RPC to an EVM-compatible blockchain network.
2. "B" is able to handle concurrent broadcasting through async methods, this for simultaneous processing of new messages from the API gateway as well as the failed messages from the "Retry" message channel.
    - Worker Pool Pattern: Create a fixed number of goroutines (workers) that listen on the retry channel. These workers process messages as they come in. This approach limits the number of concurrent operations, providing a safeguard against resource exhaustion. [method for handling currency]
3. If fail to broadcast and attempt < 3:
    - "B" will send the failed message with metadata (ie. number of retries) into the "Retry" message channel that stores failed messages with the purpose of retrying the broadcasting.
    - The "Retry" message channel will pass the retry attempt request into the "Request" message channel to send back to "B" for re-broadcasting.
4. If fail and attempt > 3:
    - The broadcasting service will send a response with the metadata of (status, message, attempts, ...) back to "A".
5. If success
    - The broadcasting service will send a response with the metadata of (status, message, attempts, ...) back to "A".


Communication Flow
1. Main Requests Channel
Purpose: This channel is used for sending new requests from Service A to Service B.
Process: Service A enqueues messages (requests) in the Main Requests Channel. Service B continuously listens to this channel, processes the incoming messages, and takes appropriate action based on the request.
2. Main Responses Channel
Purpose: Used by Service B to send responses back to Service A after processing the requests.
Process: Once Service B finishes processing a request, it sends the response data back to Service A via the Main Responses Channel. Service A listens to this channel to receive responses from Service B.
3. Retry Attempts Channel
Purpose: Handles requests that failed initially in Service B and need to be retried.
Process: If Service B encounters an error or a condition that requires a retry while processing a message, it places the message into the Retry Attempts Channel instead of responding with a failure.
Re-Queuing: Messages in the Retry Attempts Channel are typically held for a certain delay (using techniques like exponential backoff) and then re-queued into the Main Requests Channel for reprocessing.
Successful Processing and Response Flow
Service B Processing: When Service B successfully processes a request from the Main Requests Channel, it prepares a response message.
Sending Back Response: Service B then sends this response message through the Main Responses Channel.
Service A Reception: Service A listens on the Main Responses Channel and receives the response message from Service B, completing the request-response cycle.


=====

